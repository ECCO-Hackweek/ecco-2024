{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f854fa-0614-4a70-89fa-17acfc2ef9e9",
   "metadata": {},
   "source": [
    "# Data assimilation in MITgcm\n",
    "\n",
    "In this tutorial, we follow a modified MITgcm tutorial, `verification/lab_sea`, in which a regional spherical-polar coordinate ocean model is constrained to synthetic sea-surface temperature (SST) data via the adjoint method through automatic differentiation.\n",
    "\n",
    "## Goals\n",
    "1. Understanding MITgcm data assimilation workflows\n",
    "2. Gain physical intuition for what to expect when constraining a general circulation model to observational data, particularly with regards to model sensitivity to controls\n",
    "4. Probe model output using python tools `xmitgcm` and `xarray`\n",
	"\n",
    "```{tip}\n",
    "A Jupyter Notebook, [labsea_assim_tutorial](../../../assets/lab_sea/labsea_assim_tutorial) (after downloading, rename it to `labsea_assim_tutorial.ipynb`), is provided for users' convenience. It reproduces the steps and figures described in this visualization tutorial. Users can also add more sophisticated analysis on top of this notebook. \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72eeb4e-ed2c-48a3-baf2-5968c8885a2a",
   "metadata": {},
   "source": [
    "### The model\n",
    "We use a regional domain encompassing the Labrador Sea within the bounding box given by $79^\\circ E$, $41^\\circ E$,  $47^\\circ N$, and $77^\\circ N$. The domain has horizontal size $(n_x, n_y) = (16, 20)$ with $2^\\circ$ grid spacing in either horizontal direction. Unlike the verification exercises default configuration, we implement $n_z=21$ vertical levels. This tutorial takes advantage of the low number of spatial degrees of freedom combined with a short simulation time of 6 days to quickly demonstrate the key concepts to monitor when performing adjoint-based data assimilation. Higher resolution global ocean model adjoints are much more memory-intensive, but many of the same takeaways from this example will translate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796b910b-d2c3-4cce-9f5b-bcb5a7109f50",
   "metadata": {},
   "source": [
    "![alt text](labsea_bathy.png \"Labrador Sea Bathymetry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e005d-51cd-4780-a845-14a37ff5bb75",
   "metadata": {},
   "source": [
    "### Run the forward model\n",
    "The regional model is initalized with bathymetry (pictured above), initial temperature $\\theta_0$, initial salinity $S_0$, and a number of model parameters specified in `data`. For more info, please see the `input` directory. The model has been compiled with code from MITgcm `checkpoint68i` as well as a few modifications found in the `code` directory. The code directory is set up to compile the adjoint executable, but if one is just interested in simply analyzing model diagnostics or computing a misfit (but not *reducing* it), they can exclude `adjoint` from `code/packages.conf`. \n",
    "\n",
    "Let's examine some forward model output produces in the 0th run directory `run/iter0000`. We use `xmitgcm.open_mdsdataset` to load diagnostic and model grid data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f6cb4-1218-403f-894a-6cc4fa3ed387",
   "metadata": {},
   "source": [
    "### Load diagnostic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b6d04a-81c6-4a2a-aa0d-059539c6f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xmitgcm\n",
    "from xmitgcm.utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713e233-54e4-4c6c-a824-3e2ca38e4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/efs_ecco/mgoldber/MITgcm_c68i/verification/lab_sea/ecco_hackathon/'\n",
    "run_dir = root_dir + 'run/'\n",
    "run_dir0 = run_dir + 'iter0000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa89eed-20bb-4de2-bf5d-4c6beb5de5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'diags3d' # other available daily diagnostics found in this run:\n",
    "                   # diags2D, diagsEXF, diagsSI, diagsKPP\n",
    "\n",
    "ds = xmitgcm.open_mdsdataset(run_dir0,\n",
    "                        grid_dir = run_dir0,\n",
    "                        prefix = [prefix],\n",
    "                        default_dtype=np.float32,\n",
    "                        delta_t=900,\n",
    "                        ref_date='1979-01-01 00:00:00'\n",
    "                            )\n",
    "ds['XC'] = xr.where(ds.XC > 180, ds.XC - 360, ds.XC)\n",
    "ds['XG'] = xr.where(ds.XG > 180, ds.XG - 360, ds.XG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f251fb8d-69cb-480b-a676-d48d171c0291",
   "metadata": {},
   "source": [
    "### Look at model-data misfit\n",
    "The observational data used in this experiment is comprised of a single SST field occuring in the sixth record of the file `labsea_SST_fields_linear_rec006`. Our specifications in `data.ecco` instruct the model to compute a misfit between the model SST and this dataset on the sixth day of the run. Let's add the dataset to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379850d9-6b4a-4883-90b3-444a0ae20c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz, nx, ny = ds.hFacC.shape\n",
    "nday = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a1568-4bdc-4c5e-b15a-7225da0c7e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sst = read_raw_data(run_dir0 + '/labsea_SST_fields_linear_rec006', dtype=np.dtype('>f8'), shape=(nday, nx, ny))\n",
    "data_sst[data_sst==-9999] = np.nan\n",
    "ds['data_sst'] = xr.DataArray(data_sst, dims=['time','YC','XC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a19a8-b875-4a1b-a26a-3d3527dc0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = (-12, 12)\n",
    "cmap = plt.get_cmap('RdBu_r')\n",
    "cmap.set_bad(color='#d3d3d3')\n",
    "\n",
    "def plot_model_data_misfit(ds):\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    \n",
    "    model_sst = ds.THETA.isel(time=5, Z=0).where(ds.hFacC.isel(Z=0))\n",
    "    p = model_sst.plot(ax=ax1, cmap=cmap, vmin=vmin, vmax=vmax, extend='both', add_colorbar=False)\n",
    "    ax1.set_title('Model SST', fontsize=20)\n",
    "    ax1.set_ylabel('Latitude', fontsize=14)\n",
    "    ax1.set_xlabel('Longitude', fontsize=14)\n",
    "    \n",
    "    \n",
    "    data_sst = ds.data_sst.isel(time=5).where(ds.hFacC.isel(Z=0))\n",
    "    p = data_sst.plot(ax=ax2, vmin=vmin, vmax=vmax, cmap=cmap, extend='both', add_colorbar=False)\n",
    "    ax2.set_title('Data SST', fontsize=20)\n",
    "    ax2.set_ylabel('')\n",
    "    ax2.set_xlabel('Longitude', fontsize=14)\n",
    "    \n",
    "    misfit_sst_offline = (model_sst - data_sst)\n",
    "    p = misfit_sst_offline.plot(ax=ax3, vmin=vmin, vmax=vmax, cmap=cmap, extend='both', add_colorbar=False)\n",
    "    ax3.set_title('Model - Data', fontsize=20)\n",
    "    ax3.set_xlabel('Longitude', fontsize=14)\n",
    "    ax3.set_ylabel('')\n",
    "    \n",
    "    cbar_ax = fig.add_axes([0.1, -0.05, 0.8, 0.05])  # Position [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(p, cax=cbar_ax, orientation='horizontal')\n",
    "    cbar_ax.tick_params(labelsize=16)\n",
    "    cbar.ax.set_xlabel('Potential Temperature [degC]', fontsize=14)\n",
    "    \n",
    "    ax1.tick_params(axis='both', labelsize=13)\n",
    "    ax2.tick_params(axis='both', labelsize=13)\n",
    "    ax3.tick_params(axis='both', labelsize=13)\n",
    "    \n",
    "    fig.set_size_inches(12,4)\n",
    "    fig.tight_layout()\n",
    "    return fig, ax\n",
    "fig, ax = plot_model_data_misfit(ds)\n",
    "#fig.savefig('model_data_misfit_spatial.png', dpi=500, bbox_inches='tight', facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44892433-1e56-4f25-9daf-bfe8bbfa4e68",
   "metadata": {},
   "source": [
    "### Compute model-data misfit by hand\n",
    "By the end of a forward run compiled with `pkg/ecco` and `pkg/cost`, a file `costfunctionXXXX` is created containing the scalar cost functional $J:\\mathbb{R}^n\\rightarrow\\mathbb{R}$ given by\n",
    "%\\begin{equation}\\begin{split}\n",
    "%J({\\bf u}) &= \\frac{1}{2}\\left({\\bf d} - \\textbf{Obs}({\\bf u})\\right)^T{\\bf %R}^{-1}\\left({\\bf d} - \\textbf{Obs}({\\bf u})\\right)\\\\\n",
    "%&+\\frac{1}{2}({\\bf u} - {\\bf u}_0)^T{\\bf B}^{-1}({\\bf u} - {\\bf u}_0).\n",
    "%\\end{split}\\end{equation}\n",
    "$\n",
    "J({\\bf u}) = \\frac{1}{2}\\left({\\bf d} - \\textbf{Obs}({\\bf u})\\right)^T{\\bf R}^{-1}\\left({\\bf d} - \\textbf{Obs}({\\bf u})\\right) \n",
    "+\\frac{1}{2}({\\bf u} - {\\bf u}_0)^T{\\bf B}^{-1}({\\bf u} - {\\bf u}_0).\n",
    "$\n",
    "| Variable                       | Description                                                                                                          |\n",
    "|--------------------------------|----------------------------------------------------------------------------------------------------------------------|\n",
    "| $ J({\\bf u}) $                | cost function, i.e. the scalar misfit between the model and observations                              |\n",
    "| $ {\\bf d} $                   | observational data vector                         |\n",
    "| $ \\textbf{Obs}({\\bf u}) $     | observation operator giving the \"model equivalent\" to the data                                   |\n",
    "| $ {\\bf R} $                   | observational data error covariance matrix, representing the uncertainties in the observations $ {\\bf d} $       |\n",
    "| $ {\\bf u} $                   | control variables, such as initial conditions, boundary conditions (e.g. atmospheric forcing or regional open boundaries), or model parameters |\n",
    "| $ {\\bf u}_0 $                 | prior estimate of the control variables, serving as a reference or initial guess                               |\n",
    "| $ {\\bf B} $                   | background error covariance matrix, representing uncertainties in the prior estimate $ {\\bf u_0} $          |\n",
    "\n",
    "In the first term, the misfit captures the discrepency between model and data, weighted by the our uncertainty in the observations. The second term acts as a numerical regularizer for the ill-posed inverse problem, penalizing deviations from the initial guess ${\\bf u}_0$. We aim to constrain our model trajectory towards the data, thereby reducing the cost. Let's compute the misfit offline to confirm we have a full understanding of how the model is coming up with $J$.\n",
    "\n",
    "> Notation is taken from [Loose & Heimbach, 2021](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020MS002386)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e2901-d8e2-4425-b06c-5ca56c0af81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ONLINE\n",
    "# grep the cost directly from costfunctionXXXX file\n",
    "def grep_cost(run_dir, field_name='fc', ioptim=0):\n",
    "    costfunction_filename = f'{run_dir}/costfunction{ioptim:04d}'    \n",
    "    sysstr='grep ^{}.* {} | awk \\'{{print $3}}\\' |  sed \\'s/D/E/g\\''\\\n",
    "            .format(field_name, costfunction_filename)\n",
    "    grepstr = subprocess.check_output(sysstr, shell=True)\n",
    "    grepfloat = float(grepstr.decode().strip('\\n'))\n",
    "    return grepfloat\n",
    "J_online = grep_cost(run_dir0, ioptim=0)\n",
    "\n",
    "## OFFLINE\n",
    "# SST weight: spatially uniform, values of 1.042 deg C\n",
    "misfit_sst_weight = read_raw_data(run_dir0 + 'sigma_sst_p010402.bin', dtype=np.dtype('>f8'), shape=(nx, ny))\n",
    "J_offline = (((model_sst - data_sst) / misfit_sst_weight)**2).sum().values\n",
    "\n",
    "print(\n",
    "      f'online:  J_SST = {J_online:0.6e}\\n'\\\n",
    "      f'offline: J_SST = {J_offline:0.6e}\\n'\n",
    "      f'relative error = {100 * abs(J_offline - J_online)/abs(J_online):f}%'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46da5e-7797-4d33-8c1c-64ad51d2cf8a",
   "metadata": {},
   "source": [
    "### Run the adjoint code, look at gradients $\\partial J/\\partial\\text{xx}$\n",
    "We now run the adjoint model and produce *gradients* or *sensitivities*. Here, we compute gradients of $J$ with respect to controls ${\\bf u}$. The MITgcm also gives users the ability to look at sensitivites of a number of diagnostics to said controls, but here we will restrict our focus to the cost.\n",
    "\n",
    "In this run, we control the 3d initial temperature field, $\\theta_0$, and the 2d time-varying air temperature, $\\text{atemp}$. Let's form a hypothesis for what the gradients will look like: \n",
    "- $\\partial J/\\partial \\theta_0$: Recall we found that the data was warmer than the model giving rise to a negative misfit. As such, we expect that an increase in the initial temperature $\\theta_0$ should decrease the cost $J$, thus $\\partial J/\\partial T_0 < 0$.\n",
    "- $\\partial J/\\partial \\text{atemp}$: Similarly, an increase in air temperature raises sea surface temperature. Therefore we expect the same relationship for $\\partial J/\\partial \\text{atemp}$, that an increase in $\\text{atemp}$ will decrease the cost $J$, or $\\partial J/\\partial T_0 < 0$.\n",
    "\n",
    "In this simple setup, we will see that we can confirm our hypotheses. In more complicated models, however, deeper knowledge of the model dynamics is critical towards understanding the more complex sensitivities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2557788-e058-4e53-ad8f-970d659532b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dJ/dtheta\n",
    "ioptim = 0\n",
    "adxx_theta = read_raw_data(run_dir0 + f'adxx_theta.{ioptim:010d}.data', dtype=np.dtype('>f8'), shape=(nz, nx, ny))\n",
    "ds['adxx_theta'] = xr.DataArray(adxx_theta,\n",
    "                                dims=ds['THETA'].isel(time=0).dims,\n",
    "                                coords=ds['THETA'].isel(time=0).coords)\n",
    "# plot dJ/dtheta\n",
    "vmax = np.nanmax(abs(adxx_theta))\n",
    "vmin = -vmax\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "p = ds.adxx_theta.where(ds.hFacC[0]).isel(Z=0).plot(\\\n",
    "                                         x=\"XC\",y=\"YC\",\n",
    "                                         cmap=cmap, vmin=vmin, vmax=vmax, add_colorbar=False)\n",
    "cbar = fig.colorbar(p, ax=ax)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "cbar.ax.set_ylabel('[dJ/degC]', fontsize=14)\n",
    "ax.set_ylabel('Latitude', fontsize=14)\n",
    "ax.set_xlabel('Longitude', fontsize=14)\n",
    "\n",
    "ax.set_title(r'$\\frac{\\partial J}{\\partial {\\mathrm{SST}_0}}$', fontsize=30, pad = 20)\n",
    "ax.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "fig.set_size_inches(6,5)\n",
    "fig.tight_layout()\n",
    "#fig.savefig('dJdSST.png', dpi=500, bbox_inches='tight', facecolor='white')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dcbcb8-8061-4d98-bf15-407621d0f571",
   "metadata": {},
   "source": [
    "We can do the same for the 2D time-varying control $\\mathrm{atemp}$. Below, we plot snapshots of the gradients at different time lags propagating backwards in time through the adjoint run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e2b6a-a0cd-4cfe-a2bd-da6203edda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrec = nday + 1 # using knowledge of the number of records in this file \n",
    "                # read_mds would be preferable here, but I don't think it\n",
    "                # properly implements nrec\n",
    "\n",
    "adxx_atemp = read_raw_data(run_dir0 + f'adxx_atemp.{ioptim:010d}.data', dtype=np.dtype('>f8'), shape=(nrec, nx, ny))\n",
    "adxx_atemp[adxx_atemp == 0.] = np.nan\n",
    "\n",
    "fig, axes = plt.subplots(2, 3)\n",
    "\n",
    "set_cbar = True\n",
    "\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    fld = adxx_atemp[::-1][i]  # time-reversed order, how the adjoint operates\n",
    "\n",
    "    vmax = 1e3 if set_cbar else np.nanmax(abs(fld))\n",
    "    vmin = -vmax\n",
    "\n",
    "    # Add the field to the dataset for convenient lat/lon axis ticks on 2D plots\n",
    "    ds['fld'] = xr.DataArray(fld, dims=ds['rA'].dims, coords=ds['rA'].coords)\n",
    "    p = ds.fld.where(ds.hFacC[0]).plot(ax=ax, vmin=vmin, vmax=vmax, cmap=cmap, add_colorbar=False)\n",
    "\n",
    "    ax.set_title(r'$\\frac{\\partial J}{\\partial {\\mathrm{atemp}}}$' + f' (lag {i} day)', fontsize=16)\n",
    "\n",
    "    ax.set_xlabel('Longitude' if i >= 3 else '', fontsize=14)\n",
    "    ax.set_ylabel('Latitude' if i % 3 == 0 else '', fontsize=14)\n",
    "    \n",
    "cbar_ax = fig.add_axes([0.1, -0.05, 0.8, 0.03])  # Position [left, bottom, width, height]\n",
    "cbar = fig.colorbar(p, cax=cbar_ax, orientation='horizontal')\n",
    "cbar_ax.tick_params(labelsize=16)\n",
    "cbar.ax.set_xlabel('Sensitivity to air temperature [dJ/degK]', fontsize=14)\n",
    "\n",
    "fig.set_size_inches(10, 7)\n",
    "fig.tight_layout()\n",
    "\n",
    "#fig.savefig('dJdatemp.png', dpi=500, bbox_inches='tight', facecolor='white') # Vectorized PDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d783d2-ba6b-49a9-8c23-b7164f584b4c",
   "metadata": {},
   "source": [
    "As expected, the sensitivities are all negative. We can use the gradients to minimize our cost function through gradient descent.\n",
    "\n",
    "$\\mathbf{u}^{(k)} - \\alpha \\nabla J(\\mathbf{u}^{(k)})=:\\mathbf{u}^{(k+1)}$\n",
    "\n",
    "Any number of optimization libraries facilitate this step. We proceed using the library [optim_m1qn3](https://github.com/mjlosch/optim_m1qn3), which implements a limited memory quasi-Newton (L-BFGS) algorithm. Specifying the `doMainPack` option inside `data.ctrl`, we bundle up our gradient information into a binary file `ecco_ctrl_MIT_CE_000.opt0000`, hand it off to `optim_m1qn3`, and run the optimization, obtaining a ${\\bf u}^{(k+1)}$ in the file `ecco_ctrl_MIT_CE_000.opt0001`, which we refer to as the first iteration *control adjustment*. When we run our model with these perturbed controls, we will find that the cost $J$ decreases.\n",
    "\n",
    "There are various options available to the user when performing the optimization step specified in `data.optim` (see warning below). Of note, the user must indicate a desired cost reduction through e.g. the parameter `dfminFrac`. Typically, reductions of 2%-5% are attainable. Later on, we will plot the cost function reduction across 10 optimization iterations to see how well we did.\n",
    "\n",
    "> **Warning** Confusingly, `data.optim` is also an input file used by MITgcm to instruct the model what optimization iteration it is running, but this is different from the file named `data.optim` used by `optim_m1qn3`. Furthermore, both softwares use input files by the name of `data.ctrl`, but they serve completely different purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe3ea9-0b47-496a-a18b-a0abf460e032",
   "metadata": {},
   "source": [
    "### Examine control adjustments\n",
    "Below we load the adjustment made to the initial temperature control $\\theta_0$. We plot the top level of the 3D array, the initial SST adjustment. Additionally, we confirm our understanding that \n",
    "$$\\theta_0^0 + \\delta\\theta_0^1 =: \\theta_0^1$$\n",
    "where the subscripts denote initial temperature and the superscripts denote optimization iteration. Unsurprisingly, the perturbation is all positive. This makes sense knowing that the model was initially cooler than the data. In other words, the new initial condition we use for the next run is a perturbed (*warmer*, specifically) value of the old initial condition that will lead the model SST to be more similar to the data on day 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ad4be4-b720-400f-bbc3-2efcb5e5d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir0 = f'{run_dir}/iter{0:04d}/'\n",
    "run_dir1 = f'{run_dir}/iter{1:04d}/'\n",
    "\n",
    "# load control adjustments\n",
    "xx_theta = read_raw_data(run_dir1 + f'xx_theta.{1:010d}.data', dtype=np.dtype('>f8'), shape=(nz, nx, ny))\n",
    "xx_atemp = read_raw_data(run_dir1 + f'xx_atemp.{1:010d}.data', dtype=np.dtype('>f8'), shape=(nrec, nx, ny))\n",
    "xx_theta[xx_theta == 0.] = np.nan\n",
    "xx_atemp[xx_atemp == 0.] = np.nan\n",
    "\n",
    "# load initial theta\n",
    "theta0_iter0 = read_raw_data(run_dir0 + f'T.{0:010d}.data', dtype=np.dtype('>f4'), shape=(nz, nx, ny))\n",
    "theta0_iter0[theta0_iter0==0.] = np.nan\n",
    "theta0_iter1 = read_raw_data(run_dir1 + f'T.{0:010d}.data', dtype=np.dtype('>f4'), shape=(nz, nx, ny))\n",
    "theta0_iter1[theta0_iter1==0.] = np.nan\n",
    "\n",
    "# slice out SST\n",
    "SST0_iter0 = theta0_iter0[0, :, :]\n",
    "SST0_iter1 = theta0_iter1[0, :, :]\n",
    "\n",
    "# confirm that \\theta_0 + \\delta\\theta = \\theta_1\n",
    "assert np.allclose(T0_iter0 + xx_theta, T0_iter1, atol=1e-8, equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015974a-106a-4fc6-880f-ca7af1d84dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ds['xx_sst'] = xr.DataArray(xx_theta[0], dims=ds['rA'].dims, coords=ds['rA'].coords)\n",
    "\n",
    "p = ds.xx_sst.where(ds.hFacC[0]).plot(vmin = -.3, vmax = .3, cmap=cmap, add_colorbar=False)\n",
    "ax.set_title(r'$\\delta\\mathrm{SST}_0$', fontsize=30, pad=20)\n",
    "ax.set_ylabel('Latitude', fontsize=14)\n",
    "ax.set_xlabel('Longitude', fontsize=14)\n",
    "\n",
    "cbar = fig.colorbar(p, ax=ax)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "cbar.ax.set_ylabel('Potential Temperature [degC]', fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "fig.set_size_inches(6, 5)\n",
    "fig.tight_layout()\n",
    "\n",
    "# fig.savefig('delta_sst.png', dpi=500, bbox_inches='tight', facecolor='white') # Vectorized PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f546faf8-3f62-4cea-a5bf-f8eed2bf9129",
   "metadata": {},
   "source": [
    "We can repeat the process for the perturbations made to $\\mathrm{atemp}$. We find once again that the perturbations are all positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7bee4-f762-4f04-998a-11eb74466d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3)\n",
    "set_cbar = True\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    fld = xx_atemp[::-1][i]\n",
    "\n",
    "    vmax = 2e-2 if set_cbar else np.nanmax(abs(fld))\n",
    "    vmin = -vmax\n",
    "\n",
    "    # Add the field to the dataset for convenient lat/lon axis ticks on 2D plots\n",
    "    ds['fld'] = xr.DataArray(fld, dims=ds['rA'].dims, coords=ds['rA'].coords)\n",
    "    p = ds.fld.where(ds.hFacC[0]).plot(ax=ax, vmin=vmin, vmax=vmax, cmap=cmap, add_colorbar=False)\n",
    "\n",
    "    ax.set_title(r'$\\delta\\mathrm{atemp}$' + ' (lag {} day)'.format(i), fontsize=16)\n",
    "\n",
    "    ax.set_xlabel('Longitude' if i >= 3 else '', fontsize=14)\n",
    "    ax.set_ylabel('Latitude' if i % 3 == 0 else '', fontsize=14)\n",
    "    \n",
    "cbar_ax = fig.add_axes([0.1, -0.05, 0.8, 0.03])  # Position [left, bottom, width, height]\n",
    "cbar = fig.colorbar(p, cax=cbar_ax, orientation='horizontal')\n",
    "cbar_ax.tick_params(labelsize=16)\n",
    "cbar.ax.set_xlabel('Air temperature [degK]', fontsize=14)\n",
    "\n",
    "fig.set_size_inches(10, 7)\n",
    "fig.tight_layout()\n",
    "\n",
    "#fig.savefig('dJdatemp.png', dpi=500, bbox_inches='tight', facecolor='white') # Vectorized PDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83946327-6a2c-4912-a064-d3a6b26b4f55",
   "metadata": {},
   "source": [
    "### Load diagnostic data for many optimization iterations\n",
    "At this point, one runs the model from the newly obtained control perturbations. We copy `ecco_ctrl_MIT_CE_000.opt0001` into the next run directory, `run/iter0001`, and read them into the model by setting `doMainUnpack` in `data.ctrl`. Running the model forward again, one may choose to compare the diagnostics generated by `iter0000` with those from `iter0001`. The user should also confirm that the total cost in `costfunction0001` is smaller  than that of `costfunction0000`. The optimization routine is repeated until the cost has been reduced by a desired amount. We have performed 10 optimization iterations and saved the diagnostics for each.\n",
    "\n",
    "To assess our assimilation experiment, we create a wrapper to `xmitgcm.open_mdsdataset` to concatenate diagnostic datasets from multiple optimization iterations along a new axis `ioptim`. Note that this function is not particularly robust, in that we use knowledge of the directory structure:\n",
    "\n",
    "```\n",
    "run/\n",
    "â”‚\n",
    "â””â”€â”€â”€iter0000/\n",
    "â”‚   â”‚   ...\n",
    "â”‚   \n",
    "â””â”€â”€â”€iter0001/\n",
    "â”‚   â”‚   ...\n",
    "â”‚\n",
    "â”‚   ...\n",
    "â”‚ \n",
    "â””â”€â”€â”€iter0009/\n",
    "    â”‚   ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a04b19b-e2ec-48ed-89d7-ac39f0722e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_mdsdataset_optim(run_dir,\n",
    "                          nopts_max = None,\n",
    "                          iter_dir_pfx = 'iter',\n",
    "                          verbose=False,\n",
    "                          **open_mdsdataset_kwargs):\n",
    "    iter_dirs = np.sort(glob.glob(run_dir + iter_dir_pfx + '*/')).tolist()\n",
    "    iter_dirs = iter_dirs[:nopts_max]\n",
    "\n",
    "    ds_list = []\n",
    "    for this_iter_dir in iter_dirs:\n",
    "        if verbose: print(f'loading data from iter_dir={this_iter_dir}')\n",
    "        ds_i = xmitgcm.open_mdsdataset(this_iter_dir,\n",
    "                                       grid_dir = this_iter_dir,\n",
    "                                       **open_mdsdataset_kwargs)\n",
    "        ds_list.append(ds_i)\n",
    "        ds_i.close()\n",
    "    return xr.concat(ds_list, dim='ioptim')\n",
    "\n",
    "prefix = 'diags3d'\n",
    "\n",
    "ds = open_mdsdataset_optim(run_dir,\n",
    "                        prefix = [prefix],\n",
    "                        default_dtype=np.float32,\n",
    "                        delta_t=900,\n",
    "                        ref_date='1979-01-01 00:00:00'\n",
    "                            )\n",
    "ds['XC'] = xr.where(ds.XC > 180, ds.XC - 360, ds.XC)\n",
    "ds['XG'] = xr.where(ds.XG > 180, ds.XG - 360, ds.XG)\n",
    "\n",
    "nopts = len(ds.ioptim)\n",
    "print(f'diagnostics from {nopts} optimization iterations loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0903294b-f795-46f4-9c9e-c010f18c34e9",
   "metadata": {},
   "source": [
    "### Plot the cost function reduction\n",
    "We find that from optimization iteration one to two, a considerable decrease in the cost is achieved. After a few more iterations, the cost plateaus. This is the first indicator of a successful assimilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e056984f-dac3-490d-ac6a-c4af02ddfd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = []\n",
    "for ioptim in range(nopts):\n",
    "    run_dir_i = f'{run_dir}/iter{ioptim:04d}'\n",
    "    costfunction_filename = f'{run_dir_i}/costfunction{ioptim:04d}'\n",
    "    field_name = 'fc'\n",
    "    costs.append(grep_cost(run_dir_i, ioptim=ioptim))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(nopts)\n",
    "ax.plot(x, costs, 'k')#, alpha=.5)\n",
    "ax.scatter(x, costs, c='k')#, alpha=.5)\n",
    "ax.set_title(r'Cost function', fontsize=30, pad=20)\n",
    "ax.set_ylabel(r'$J$', fontsize=18)\n",
    "ax.set_xlabel('Iteration', fontsize=18)\n",
    "ax.semilogy()\n",
    "yticks = [1e7, 5e6, 1e6, 5e5]\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_xticks(np.arange(nopts))\n",
    "ax.set_ylim(1e6, 4e7)\n",
    "ax.tick_params(axis='both', labelsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b446c18c-639c-499a-a279-cb7e815494cf",
   "metadata": {},
   "source": [
    "### Visualize the misfit reduction\n",
    "Lastly, we can give a qualitative \"eye test\" to assure that the assimilation did what we expected by looking at the model SST on day 6 before and after optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b93c0b-dd86-4601-93ed-5a62cb078b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-add the observational data to the dataset\n",
    "ds['data_sst'] = xr.DataArray(data_sst, dims=['time','YC','XC'])\n",
    "\n",
    "fig, ax = plot_model_data_misfit(ds.isel(ioptim=0))\n",
    "fig.suptitle('Iteration 0', fontsize=30, y = 1.2)\n",
    "\n",
    "fig, ax = plot_model_data_misfit(ds.isel(ioptim=9))\n",
    "fig.suptitle('Iteration 9', fontsize=30, y = 1.2);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec27ec9f-7455-4807-9369-607b75ca3270",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Eureka! ðŸ’¡\n",
    "As we had hoped the model SST on day 6 looks much more similar to the observational data after optimization. Moreover, the spatial plot of the misfit is clearly nearer to zero almost everywhere. \n",
    "\n",
    "### Conclusion\n",
    "We demonstrated the workflows used to assimilate synthetic observational data into an unconstrained MITgcm model. Along the way, we investigated model diagnostics, sensitivity to controls, control perturbations, and cost function reduction across iterations. The reader is encouraged to play with different model parameters in `data`, explore other options for $J$ such as boxmean quantities of interest ([more info here](https://mitgcm.readthedocs.io/en/latest/ocean_state_est/ocean_state_est.html)), and further probe changes in model diagnostics between iteration 0 and 9 to understand exacly how the physics of the model changed in order to accomodate the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
